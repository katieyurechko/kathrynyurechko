<!DOCTYPE html>
<html lang="en">
<head>
<link rel="icon" href="https://media.licdn.com/dms/image/D4E03AQF961Cgo3xCTQ/profile-displayphoto-shrink_200_200/0/1677295637294?e=1693440000&v=beta&t=kf9o1VsPJWK3Dd93fUJs7lryE-ID4FY_cSIfQOf87Zw">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<title>Kathryn Yurechko</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
* {
  box-sizing: border-box;
}

/* Style the body */
body {
  font-family: 'Lato';
}

/* Column container */
.row {  
  display: -ms-flexbox; /* IE10 */
  display: flex;
  -ms-flex-wrap: wrap; /* IE10 */
  flex-wrap: wrap;
  margin-left: 200px;
  margin-right: 200px;
  margin-top: 200px;
  margin-bottom: 200px;
}

/* Create two unequal columns that sits next to each other */
/* Sidebar/left column */
.side {
  -ms-flex: 40%; /* IE10 */
  flex: 40%;
  background-color: white;
  padding: 20px;
}

/* Main column */
.main {   
  -ms-flex: 60%; /* IE10 */
  flex: 60%;
  background-color: white;
  padding: 20px;
}

/* Responsive layout - when the screen is less than 700px wide, make the two columns stack on top of each other instead of next to each other */
@media screen and (max-width: 700px) {
  .row {   
    flex-direction: column;
  }
}

/* Responsive layout - when the screen is less than 400px wide, make the navigation links stack on top of each other instead of next to each other */
@media screen and (max-width: 400px) {
  .navbar a {
    float: none;
    width: 100%;
  }
}

footer {
    padding: 10px 20px;
    background-color: #D8BFD8;
    color: white;
    font-family: Lato, Helvetica, sans-serif;
    text-align: center;
    font-size: 12;
}
  
</style>
</head>
<body>
  
<div class="row">
  <div class="side">
    <h3>Policy Proposal</h3>
    <h4>For the Truman Scholarship, "the nation's premiere scholarship for students interested in public service." (The Harry S. Truman Scholarship Foundation)</h4>
    <h5>Winter 2023</h5>
  </div>
  <div class="main">
    <p><b>To:</b> Senator Ben Ray Luján</p>
    <p><b>Office Held:</b>Chair, Subcommittee on Communications, Media, and Broadband, for the U.S. Senate Committee on Commerce, Science, and Transportation</p>
    <p><b>Issue:</b> Algorithmic Transparency on Social Media</p>
    <br>
    <p><b>Problem Statement</b></p>
    <p>The lack of transparency in social media algorithms is among the most pressing issues in the United States. According to the Pew Research Center, approximately 239 million Americans use social media, but only 300 to 400 experts understand and determine how social media algorithms work (MIT 2022). </p>
    <p>Cloaked in opacity, social media algorithms cause harm. They reinforce systemic biases, wrongly flagging tweets by Black users as hateful 1.5 times more than tweets by white users (ACL Anthology 2019). They leverage addictive design techniques to generate profits at the expense of public health, causing 5% to 10% of Americans to develop social media addictions that mirror gambling and drug dependencies (Addiction Center 2019). To increase user engagement, they bombard users with divisive content—with Meta’s algorithms resulting in 64% of all extremist group joins in 2016 and later fueling the 2020 attack on the U.S. Capitol (WSJ 2020; WaPo 2021).</p>
    <p>Social media algorithms operate largely in the absence of critical analysis and hold unrestrained power to threaten both individual wellbeing and American democracy.</p>
    <br>
    <p><b>Proposed Solution</b></p>
    <p>The Digital Services Act of 2022 became Europe’s first major legislation requiring online services to provide data to researchers. Similar acts in the U.S., including the Platform Accountability and Transparency Act introduced in 2021, have failed to address the problem— they compel social media companies to make their algorithms more transparent rather than incentivize them.</p>
    <p>I propose establishing a Platform Transparency Office (PTO) within the Federal Trade Commission, built on the model of the global LEED (Leadership in Energy and Environmental Design) certification program. Just as LEED incentivizes companies and individuals to adopt green building standards by awarding LEED ratings, the PTO could incentivize social media companies to practice algorithmic transparency by awarding platforms an Algorithmic Transparency Certification, enabling the PTO to support platforms’ business models of sustaining user engagement amongst backlash over algorithmic opacity.</p>
    <p>The first step in practicing transparency would be for social media companies to provide the source code for their algorithms to selected researchers. The PTO could open a request for proposal to research universities, selecting 8-10 institutions that present best concepts and strategies for conducting algorithms research. Selected universities would sign legal documents to protect the source code, which they would receive via privacy-protected pathways, and would publish annual algorithms reports to improve algorithmic transparency.</p>
    <br>
    <p><b>Major Obstacles/Implementation Challenges</b></p>
    <p>Despite bipartisan support for regulating social media, industry lobbying has delayed hundreds of U.S. proposals to regulate platforms (Center for Humane Technology 2022). This necessitates highlighting the potential benefits of this policy to social media companies, including the satisfaction of increasingly conscientious users.</p>
    <p>An attempt to rectify the over-censorship of marginalized voices online through algorithms research may engender a fear of censorship in those with identities of power. Those with extremist ideologies may similarly fear that it would erase their online presence.</p>
    <p>Finally, although research can investigate algorithmic harms, it may be insufficient to drive improvements in platform practices. Dividing the Algorithmic Transparency Certification into designation levels based on the number of researcher recommendations that platforms adopt will encourage adherence to researcher recommendations.</p>
    <p>This policy was designed with resistance in mind by facilitating opportunities for researchers who will encourage social media companies to rectify algorithmic harms, fostering a digital realm that upholds American wellbeing and democratic values.</p>
    <br>
    <p><b>References, Footnotes, and Exhibits</b></p>
    <p>Hilliard, Jena. “Social Media Addiction.” <em>Addiction Center</em>, 15 July 2019, https://www.addictioncenter.com/drugs/social-media-addiction/.</p>
    <p>Horwitz, J., & Seetharaman, D. “Facebook Executives Shut Down Efforts to Make the Site Less Divisive.” <em>The Wall Street Journal</em>, 26 May 2020, https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499.</p>
    <p>Krass, Peter. “Transparency: The First Step to Fixing Social Media.” <em>MIT Initiative on the Digital Economy</em>, 5 Apr. 2022, https://ide.mit.edu/insights/transparency-the-first-step-to-fixing-social-media/. </p>
    <p>Maarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi, and Noah A. Smith. 2019. The Risk of Racial Bias in Hate Speech Detection. <em>In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 1668–1678, Florence, Italy. Association for Computational Linguistics.</p>
    <p>“Policy Brief: State of Global Tech Policy.” <em>Center for Humane Technology</em>, 19 Sept. 2022, https://www.humanetech.com/insights/policy-brief-state-of-global-tech-policy.</p>
    <p>Timberg, C., Dwoskin, E., & Albergotti, R. “Inside Facebook, Jan. 6 violence fueled anger, regret over missed warning signs.” <em>The Washington Post</em>, 22 Oct. 2021, https://www.washingtonpost.com/technology/2021/10/22/jan-6-capitol-riot-facebook/.</p>
  </div>
</div>

<footer>
    <p>This site was built by &copy; Kathryn Yurechko, <a href="https://github.com/amyxzhang/personal_website">GitHub code here</a>.</p>
</footer>

</body>
</html>
