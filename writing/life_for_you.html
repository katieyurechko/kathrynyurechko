<!DOCTYPE html>
<html lang="en">
<head>
<link rel="icon" href="https://media.licdn.com/dms/image/D4E03AQF961Cgo3xCTQ/profile-displayphoto-shrink_200_200/0/1677295637294?e=1693440000&v=beta&t=kf9o1VsPJWK3Dd93fUJs7lryE-ID4FY_cSIfQOf87Zw">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<title>Kathryn Yurechko</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
* {
  box-sizing: border-box;
}

/* Style the body */
body {
  font-family: 'Lato';
}

/* Column container */
.row {  
  display: -ms-flexbox; /* IE10 */
  display: flex;
  -ms-flex-wrap: wrap; /* IE10 */
  flex-wrap: wrap;
  margin-left: 200px;
  margin-right: 200px;
  margin-top: 200px;
  margin-bottom: 200px;
}

/* Create two unequal columns that sits next to each other */
/* Sidebar/left column */
.side {
  -ms-flex: 40%; /* IE10 */
  flex: 40%;
  background-color: white;
  padding: 20px;
}

/* Main column */
.main {   
  -ms-flex: 60%; /* IE10 */
  flex: 60%;
  background-color: white;
  padding: 20px;
}

/* Responsive layout - when the screen is less than 700px wide, make the two columns stack on top of each other instead of next to each other */
@media screen and (max-width: 700px) {
  .row {   
    flex-direction: column;
  }
}

/* Responsive layout - when the screen is less than 400px wide, make the navigation links stack on top of each other instead of next to each other */
@media screen and (max-width: 400px) {
  .navbar a {
    float: none;
    width: 100%;
  }
}

footer {
    padding: 10px 20px;
    background-color: #D8BFD8;
    color: white;
    font-family: Lato, Helvetica, sans-serif;
    text-align: center;
    font-size: 12;
}
  
</style>
</head>
<body>
  
<div class="row">
  <div class="side">
    <h3>Life for You</h3>
    <h5>May 21st, 2022</h5>
  </div>
  <div class="main">
    <p>Social media has arguably become an integral part of what it means to be human. In the twenty-first century, children, parents, and even grandparents delve into their personalized online feeds, consuming Facebook, Instagram, Twitter, and TikTok content about politics, pop culture, and more. Their “For You” pages (as TikTok terms them) give users recommendations regarding what they should buy and whom they should “friend.” But while our digital worlds consistently curate and optimize our feeds, we find our stream of real life interactions to be increasingly less ideal. It is difficult to find romantic partners, make friends, and even determine places to shop or eat that produce the almost certain dopamine hits that our social media pages provide. What if we could navigate a society of seemingly endless information with maximal efficiency, comfort, and pleasure? Thankfully, “Life For You” provides a solution. It makes our beloved social media algorithms a part of ourselves.</p>
    <br>
    <p>By wearing a small, noninvasive piece of sensor technology coupled with an eye implant, an algorithm can suggest a real life feed even more optimal than that on your screen. “Life For You” (LFY) measures your “happy chemical” and “sad chemical” levels, facial expressions, body language, and other invisible or largely hidden indicators of emotion. Dialogue triggers an audio component in the sensor, which inputs the types of words that you use as well as how you use them to calculate the enjoyability of each conversation. Global positioning technology in the sensor obtains your physical location, allowing the algorithm to use the duration of time that you spend in a place or in someone’s company for optimization. Finally, the eye implant scans your field of vision to incorporate visual cues. LFY utilizes these preference/pleasure indicators to calculate personalized and consistently updated ratings of your compatibility with each person and place. Its algorithm initially gives all individuals and establishments within your localized radius a rating based on your demonstrated preferences; it then fine-tunes these ratings using your interactions. It displays compatibility scores in your visual field on a scale from zero to one hundred percent, offering you a numeric guide every time you view a person or institution. A final feature of LFY is its incorporation of a blocking technology. If your compatibility rating of a person or place is below 10%, LFY blots them out both visually and audibly.</p>
    <br>
    <p>LFY serves as an enhanced form of the technology seen in <em>Black Mirror</em>’s “Nosedive” (abbreviated NT). It makes life more ideal without falling prey to the pivotal pitfalls of the NT. First, while the NT lets one number define you, your LFY compatibility ratings vary from person to person. There is no universal rating that aims to override your personality; though the NT labeled Susan as a 1.4 to everyone, LFY now understands that Susan’s engagements with some would make her closer to a 5 for them personally. The NT’s universal ratings let entire establishments determine what you do or do not deserve (e.g., access to their premises, particular benefits, etc.). Now, LFY helps you use others’ ratings to make your interactions more efficient. You do not need to waste time getting to know someone who is not even compatible with you. Instead, you can utilize your personalized rating of them as a trustworthy guide. Second, the NT operates by having others rate you, which encourages you to change yourself to better appeal to those around you. LFY instead displays how compatible others would be with you. You can find people who are most like you without sacrificing any of your personal qualities. LFY even helps you choose places that are most aligned with your preferences. Additionally, rather than updating ratings by the often biased or unthinking swipes of thumbs, the LFY algorithm uses sensory information to determine your compatibility with others objectively. It knows you better than you know yourself, so there is no need to waste time interpreting messy emotions or struggling to avoid faults in your senses. You can listen to the algorithm, which knows what is best for you. Finally, the NT allows anyone anywhere to see your rating. With LFY, only those who directly engage with you can view a rating that is personalized for them. There is no need to worry about interviewers or your significant others’ parents judging you by a published number. The blocking feature in LFY also helps to protect you from unpleasant experiences. Unlike the NT, it supports you personally in pursuing encounters that you would enjoy while shielding you from subpar engagements and their potential negative consequences.</p>
    <br>
    <p>Though LFY (the corporation) broadcasts these statements in alluring commercials, it is important to consider the dangers posed by what they depict as a seemingly innocuous technology. Some critical similarities with the flawed NT remain, including the assignment of numeric ratings to human beings. Associated with the ratings of establishments, the human ratings in LFY might further propel us to treat one another like purchasable objects. LFY’s use of the blocking feature heightens this concern, since blocking a person or place is essentially like returning a person or a group of people to a store because they did not fit you perfectly. It encourages us to avoid the “emotional strain of a confrontation,” ultimately inhibiting us from learning the truth of others’ experiences (Canca et al. 73). The identification of human with business ratings highlights the dehumanization associated with corporate power. LFY would likely direct people to particular establishments as if they themselves were products. It would support corporations in becoming political agents that could create their own autocracy by paying LFY (the corporation) for certain ratings in consumers’ eyes.</p>
    <br>
    <p>Various philosophers describe that “in the real world, we always have choices and there is no escaping that fact” (Cleary et al. 171). However, LFY would likely enable us to evade the burden of choice. By adhering to the scientific rationality of LFY’s algorithm, we could let technology dictate our relationships and engagements for us. But in trading in freedom for efficiency, we would limit our ability to engage in the significant political decisions that impact our futures, finding an eerily freedom-like “unfreedom” in the higher standard of living that LFY’s purchasing optimization would likely produce (Marcuse 1). In a predominant LFY culture, remaining freedoms like the freedom of speech might encourage people to believe that they have a say in a covertly oppressive system. Ethan Harris describes the ability of personalized feeds to hinder our capacities for democratic judgement. He writes that “while social media is sometimes viewed as the modern ‘public square’ for free expression, its algorithms actually work to undermine democratic culture by separating those with opposing views into ‘echo chambers’ that increase polarization…and pressure users to hold and act on increasingly radical beliefs” (Harris). It is probable that by encouraging us to follow paths of compatible people and places, LFY would promote a more polarized and extreme society. Though social media presently fosters “digital communities based on tribal conflicts,” we could tend toward segregated physical communities in which “non-conformity with the system itself appears to be socially useless,” especially since LFY would threaten economic hardships and deleted relationships with its blocking feature (De-Wit et al.; Marcuse 2).</p>
    <br>
    <p>Finally, humans tend not to prefer things that cause them discomfort, but we need these things socially, ethically, and politically. The compatibility- and efficiency-driven mindset of LFY would likely propel us toward convenient, conflict-free engagements. As Herbert Marcuse writes, the “supreme promise” of a system like LFY is “an ever-more-comfortable life” (23). However, constant comfort would limit our ability to experience the fullness of the world around us. Daoist thinking posits that conflicting emotions are not self-standing. Rather, they exist in co-constitutive binaries. We need happiness to feel sadness and sadness to feel happiness; each emotion serves for the other as a meaningful and necessary contrast (Tzu 6). LFY would likely drain humankind of worthwhile emotional distinctions. It would leave only a dullness by encouraging disengagement with issues that make us uncomfortable. The blocking feature of LFY especially suggests “a paternalistic state, where extreme measures are taken to avoid any possibility of harm” (Canca et al. 75). But a one-dimensional reality hinders our freedom to see the depth of the world around us. It limits our capacity to take meaningful, necessary stands for ourselves and for one another.</p>
    <br>
    <p>One way to depict these possibilities is to share them through a story. Imagine a world in which LFY is installed in every person. A high-school-aged girl moves to a city with her family, but the perils of attending a new school are largely nonexistent. Thanks to LFY, she finds it easy to make friends and follow them to activities that she enjoys. School itself is not challenging. Years ago, students prompted a mass exodus of teachers from classrooms by opting only to take classes with those whom they liked the most. Those that spoon-fed them material through handouts and in-class movies won. They made “learning” the most pleasurable, and that is what students wanted.</p>
    <br>
    <p>One day, on her way to school, the girl notices a gated community of blotted-out figures. One jumps over the gate and into her view, murmuring things that she cannot understand. She runs, finding an old building with ivy scaling its outer wall, and she hesitates. Its rating is the lowest that she has ever seen. But she has never felt such fear, so she enters, slamming the door behind her. An elderly woman appears bewildered from behind a dusty desk. The girl explains that she just needs to wait a moment; a blurry, muffled figure startled her on the street. The woman rolls her eyes in silence, expressing a pitiful resignation, but as the girl begins to observe the space, she appears to grow curious. The woman hesitates to offer an explanation—the more she makes people uncomfortable, the more their ratings eradicate her from existence. But she longs for connection. The girl looks interested. So, she shares the story.</p>
    <br>
    <p>The building is called a library, and it houses many books. People used to come read them and expand their minds. But mind expansion hurts, and no one in today’s world wants to experience discomfort. Social media prompted a shift from Shakespeare to CliffsNotes; book stores became movie stores to accommodate people’s preferences; companies like Netflix sent lofty sums to LFY to drive libraries into nonexistence. The librarian is shocked that the girl even entered the space with its now-universal rating of 15%. But the girl marvels at dinosaurs, delving into the books that went extinct.</p>
    <br>
    <p>She marches into school the next day with posters exclaiming “Ignore the ratings!”, “Books <em>ARE</em> real,” and “Let me tell you about the Holocaust.” Students scowl at her. Even her friends are uncomfortable, which forces them to consider how the algorithm could get their compatibility ratings so wrong. Soon, the girl gets called into the principal’s office. School officials threaten expulsion for her challenging of the educational norm, but she refuses to quit. Having seen the truth, she goes back to the library and asks the librarian if she can borrow some books. She loads them into a shopping cart and pushes open the school’s doors, aiming to disseminate copies of <em>To Kill A Mockingbird</em>, <em>The Outsiders</em>, and other classics that we know today. But she soon realizes that she has been blocked by the other students’ algorithms. They are unwilling to take the books, and this entire story lives in a novel called Black Mirror, decaying on the shelves of today’s libraries as they gradually shut down.</p>
    <br>
    <p>LFY calls us to question our contemporary engagement with social media. We give content-generating algorithms and screens so much of ourselves, yet we often fail to ask whether life <em>for us</em> is worth its potential costs. We seem willing to sacrifice endlessly for the efficiency and comfort afforded by technologies, but as the scenario demonstrates, technological solutions tend to create new problems. Like the girl, we must challenge ourselves to enter into abandoned realms of ideas. We must share the beauty of what we are increasingly taught to avoid, and we can, while we still have the chance.</p>
    <br>
    <h4>Works Cited</h4>
    <p>Canca, Cansu, et al. “White Christmas and Technological Restraining Orders: Are Digital Blocks Ethical?” <em>Black Mirror and Philosophy: Dark Reflections</em>, Wiley-Blackwell, Hoboken, NJ, 2020, pp. 71–79.</p>
    <p>Cleary, Skye, et al. “Hang the DJ and Digital Dating: Should We Use Computers to Help Us Find Mates?” <em>Black Mirror and Philosophy: Dark Reflections</em>, Wiley-Blackwell, Hoboken, NJ, 2020, pp. 168–176.</p>
    <p>De-Wit, Lee, et al. “Are Social Media Driving Political Polarization?” <em>Greater Good Magazine</em>, Berkeley, 16 Jan. 2019, https://greatergood.berkeley.edu/article/item/is_social_media_driving_political_polarization. </p>
    <p>Harris, Ethan. “Algorithms Are Censoring US.” <em>Northeastern University Political Review</em>, 12 Feb. 2021, https://www.nupoliticalreview.com/2021/02/16/algorithms-are-censoring-us/. </p>
    <p>Marcuse, Herbert. <em>One-Dimensional Man</em>. Beacon Press, 1964. </p>
    <p>“Nosedive.” <em>Black Mirror</em>, created by Charlie Booker, season 3, episode 1, House of Tomorrow, 2016.</p>
    <p>Tzu, Lao. <em>Tao Te Ching</em>. Penguin Books, 1963.</p>
  </div>
</div>

<footer>
    <p>This site was built by &copy; Kathryn Yurechko, <a href="https://github.com/amyxzhang/personal_website">GitHub code here</a>.</p>
</footer>

</body>
</html>
